# 分库分表

## 1、为什么要分库分表？

单机的存储能力、连接数、QPS是有限的，分库分表是一种很好的优化手段，将大表拆分到不同库不同表，减轻数据量，提高查询性能。

## 2、分库分表的技术有哪些？

- mycat

> 需要部署，自己运维一套中间件，运维成本高，但是好处在于对于各个项目是透明的，如果遇到升级之类的都是自己中间件那里搞就行了。

- sharding-jdbc

> 优点在于不用部署，运维成本低，不需要代理层的二次转发请求，性能很高，但是如果遇到升级啥的需要各个系统都重新升级版本再发布，各个系统都需要耦合sharding-jdbc 的依赖。

## 3、分库分表的拆分方式有？他们分别主要解决什么问题？

- 垂直拆分

> 把一个有很多字段的表给拆分成多个表，或者是多个库上去，每个库表的结构都不一样，每个库都都包含部分字段。一般来说会将较少的访问频率很高的字段放到一个表里去，然后将较多的访问频率很低的字段放到另外一个表里去。因为数据库是有缓存的，你访问频率高的行字段越少，就可以在缓存里缓存更多的行，性能就越好。这个一般在表层面做的较多一些。

- 水平拆分

> 表结构相同，拆分到多张表，这多张表可以在同一个库也可以在不同库，然后采取算法（比如哈希）将数据分散到多张表里，减轻单表的压力。

## 4、单张大表要进行分库分表怎么办？

> 大表怎么优化？某个表有近千万数据，CRUD比较慢，如何优化？
>
> 分库分表。

**(1) 停机迁移方案**

停机迁移方案中，就是把系统在凌晨 12 点开始运维，系统停掉，然后提前写好一个导数据的一次性工具，此时直接跑起来，然后将单库单表的数据写到分库分表里面去。 导入数据完成了之后，修改系统的数据库连接配置，然后直接启动连到新的分库分表上去。

**(2) 双写迁移方案**

此方案不用停机，比较常用。 简单来说，就是在线上系统里面，之前所有写库的地方，增删改操作，都除了对老库增删改，都加上对新库的增删改，这就是所谓的双写。同时写两个库，老库和新库。然后系统部署之后，新库数据差太远，用之前说的导数据工具，跑起来读老库数据写新库，写的时候要根据，判断下读出来的数据在新库里没有，或者是根据更新时间对比，比新库的数据新才会写。

## 5、分库分表有哪些算法？

比如：

- 数据分段

> 比如：user_id属于[0, 100万]为0库，属于[100万, 200万]为2库。以此类推。优点：简单、数据均衡、扩容简单。缺点：因为未知最大值，所以无法用时间戳作为key，这个方法不能用表的自增主键，因为每个表都自增数量不是统一维护。所以需要有一个发号器或发号系统做统一维护key自增的地方。
>
> 推荐日志表可以按照此方式，按照时间来分，比如一个月一张表。

- hash取模

> 比如：user_id%2=0为0库，user_id%2=1为1库。优点：简单、数据均衡、负载均衡。缺点：扩容困难，要迁移数据，%2变%3麻烦。

- 一致性哈希

> hash取模简单粗暴，但是涉及到数据迁移的很多，几乎全部挪动。一致性哈希可以解决这个问题，但是也无法避免数据不迁移，只是迁移的少了而已，一般分布式缓存用一致性哈希居多，具体如下：
>
> 假设分为4个库，每个库16张表。
>
> 库：一致性哈希算法(库的标识 [比如ip]) % 2^32
>
> 数据：一致性哈希算法(key) % 2^32，然后对比四个库的哈希值，看看哪个最小就放到哪个库里，也就是顺时针找最近的节点。然后再取模16找到具体在哪个表里。
>
> 优点：四个库不够用了，多加一个库，那么只需要迁移四分之一的数据即可，不需要全部迁移。

## 6、分库分表后面临的问题

- 分布式事务问题

> TCC、LCN、Seata、本地消息表、RocketMQ

- 分页、排序、跨库聚合统计等问题

> 一般做法是分N次查询，然后业务代码里自己进行分页、排序或聚合

- 跨库join

> 一般做法是分N次查询，然后业务代码里自己组装数据

- 全局主键

> 分布式id。
>
> - UUID
> - 数据库自增id
> - Redis
> - 号段模式
> - 雪花算法
> - 美团Leaf：支持号段模式+雪花算法


---
收录时间: 2021/01/05

<Vssue :title="$title" />